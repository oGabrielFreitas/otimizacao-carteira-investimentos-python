{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc76ab7",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "source": [
    "# Otimiza√ß√£o de Markowitz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca834bd8",
   "metadata": {},
   "source": [
    "## Explica√ß√£o"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3757a9e",
   "metadata": {},
   "source": [
    "### √çndice Sharpe\n",
    "\n",
    "Mede a rentabilidade em rela√ß√£o √† volatilidade da carteira. √â normalmente apresentado junto com a volatilidade l√≠quida e a rentabilidade l√≠quida.\n",
    "\n",
    "Se considerarmos o CDI como ativo livre de risco, a f√≥rmula fica:\n",
    "\n",
    "<div style=\"text-align: left\">\n",
    "\n",
    "$$\n",
    "\\frac{\\text{rentabilidade do ativo} - \\text{CDI}}{\\text{volatilidade do ativo}}\n",
    "$$\n",
    "\n",
    "</div>\n",
    "\n",
    "\n",
    "Em alguns casos, podemos desconsiderar o ativo livre de risco. Por exemplo:\n",
    "\n",
    "Se o retorno foi 20% e a volatilidade foi 10%, o Sharpe do investimento √© 2.\n",
    "\n",
    "---\n",
    "\n",
    "### F√≥rmula can√¥nica\n",
    "\n",
    "<div style=\"text-align: left\">\n",
    "\n",
    "$$\n",
    "\\text{Sharpe} = \\frac{R_p - R_f}{\\sigma_p}\n",
    "$$\n",
    "\n",
    "</div>\n",
    "\n",
    "* \\(R_p\\) ‚Äî retorno m√©dio do ativo ou portf√≥lio  \n",
    "* \\(R_f\\) ‚Äî taxa livre de risco (ex.: CDI, T‚Äëbill)  \n",
    "* \\(\\sigma_p\\) ‚Äî volatilidade (desvio padr√£o) dos retornos de \\(R_p\\)\n",
    "\n",
    "Essa f√≥rmula mede o **retorno excedente por unidade de risco total**.\n",
    "\n",
    "---\n",
    "\n",
    "### Quando se usa \\(R_f = 0\\)\n",
    "\n",
    "| Situa√ß√£o | Por qu√™? |\n",
    "| --- | --- |\n",
    "| Exemplos did√°ticos | Para simplificar a explica√ß√£o e a matem√°tica. |\n",
    "| S√©ries j√° em *excess return* | O retorno livre de risco j√° foi subtra√≠do. |\n",
    "| Frequ√™ncia di√°ria ou intradi√°ria | A taxa di√°ria do CDI √© desprez√≠vel. |\n",
    "| Ambientes com juro ‚âà 0% | Comuns ap√≥s 2008 em EUA, Europa ou Jap√£o. |\n",
    "| Estrat√©gias *self-financing* | O retorno j√° √© l√≠quido de funding (ex.: market-neutral). |\n",
    "\n",
    "---\n",
    "\n",
    "### Exemplo\n",
    "\n",
    "* Retorno anual do ativo: **20%**  \n",
    "* CDI anual: **12%**  \n",
    "* Volatilidade anual: **10%**\n",
    "\n",
    "<div style=\"text-align: left\">\n",
    "\n",
    "$$\n",
    "\\text{Sharpe} = \\frac{0.20 - 0.12}{0.10} = 0.8\n",
    "$$\n",
    "\n",
    "</div>\n",
    "\n",
    "*Se \\(R_f = 0\\), o mesmo caso daria Sharpe = 2.*\n",
    "\n",
    "---\n",
    "\n",
    "### Como funciona a otimiza√ß√£o\n",
    "\n",
    "O objetivo da otimiza√ß√£o de Markowitz √© **encontrar a carteira com o maior √≠ndice de Sharpe**.\n",
    "\n",
    "Por qu√™?  \n",
    "Porque quanto maior o Sharpe, **maior o retorno esperado para cada unidade de risco** (volatilidade) assumido. Isso significa melhor efici√™ncia na rela√ß√£o risco-retorno.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5cc7fe6",
   "metadata": {},
   "source": [
    "# C√≥digo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41bcd25",
   "metadata": {},
   "source": [
    "## Importa√ß√µes e Fun√ß√µes Auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43db41f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mplcyberpunk\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import scipy.optimize as minimize\n",
    "import matplotlib.ticker as mticker\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d270dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mostrar_top_carteiras(vetor_ordenacao, vetor_retornos_esperados, tabela_pesos, tickers, top_n=10, nome_ordenacao=\"√çndice\"):\n",
    "    \"\"\"\n",
    "    Exibe um DataFrame com as top carteiras ordenadas por uma m√©trica (Sharpe, Sharpe penalizado, etc.).\n",
    "\n",
    "    Par√¢metros:\n",
    "    - vetor_ordenacao: vetor com a m√©trica a ser usada para ordena√ß√£o (ex: vetor_sharpe, vetor_sharpe_penalizado)\n",
    "    - vetor_retornos_esperados: vetor com retornos logar√≠tmicos esperados anualizados (252 dias)\n",
    "    - tabela_pesos: matriz com os pesos dos ativos para cada carteira\n",
    "    - tickers: lista dos nomes dos ativos\n",
    "    - top_n: n√∫mero de carteiras a exibir (default = 10)\n",
    "    - nome_ordenacao: nome da m√©trica que est√° sendo usada (s√≥ para exibi√ß√£o)\n",
    "    \"\"\"\n",
    "    # Converte log-retorno em retorno aritm√©tico anual\n",
    "    retornos_anuais_aritmeticos = np.exp(vetor_retornos_esperados) - 1\n",
    "\n",
    "    # Ordena os √≠ndices do vetor de ordena√ß√£o (maior para menor)\n",
    "    indices_ordenados = np.argsort(vetor_ordenacao)[::-1]\n",
    "\n",
    "    # Monta tabela com retornos e pesos\n",
    "    dados_tabela = []\n",
    "    for i in indices_ordenados[:top_n]:\n",
    "        linha = {\n",
    "            'Retorno Esperado (%)': f'{retornos_anuais_aritmeticos[i] * 100:.2f}',\n",
    "            nome_ordenacao: f'{vetor_ordenacao[i]:.4f}'\n",
    "        }\n",
    "        for j, ticker in enumerate(tickers):\n",
    "            linha[ticker] = f'{tabela_pesos[i, j] * 100:.2f}%'\n",
    "        dados_tabela.append(linha)\n",
    "\n",
    "    df_resultado = pd.DataFrame(dados_tabela)\n",
    "\n",
    "    print(f\"\\nüìã Top {top_n} carteiras ordenadas por: {nome_ordenacao}\\n\")\n",
    "    return df_resultado\n",
    "\n",
    "\n",
    "def plot_fronteira_eficiente(volatilidades, retornos, vetor_ordenacao, titulo=\"Fronteira Eficiente\",\n",
    "                              label_ordenacao=\"Sharpe\", cor_destaque='red', idx_vizinho=None, idx_otimo=None):\n",
    "    \"\"\"\n",
    "    Gera o gr√°fico da fronteira eficiente com destaque para:\n",
    "    - melhor carteira segundo a m√©trica fornecida\n",
    "    - uma carteira \"vizinha\" (ex: 900¬™ melhor)\n",
    "    \"\"\"\n",
    "    # Corrige: converte retornos de logar√≠tmico para aritm√©tico\n",
    "    retornos_aritmeticos = np.exp(retornos) - 1\n",
    "    retornos_pct = retornos_aritmeticos * 100\n",
    "    vols_pct = volatilidades * 100\n",
    "\n",
    "    # Para a fronteira, ordenar apenas para a linha\n",
    "    indices_ordenados = np.argsort(vols_pct)\n",
    "    vols_ordenados = vols_pct[indices_ordenados]\n",
    "    retornos_ordenados = retornos_pct[indices_ordenados]\n",
    "\n",
    "    fronteira_vols = []\n",
    "    fronteira_rets = []\n",
    "    max_ret = -np.inf\n",
    "    for vol, ret in zip(vols_ordenados, retornos_ordenados):\n",
    "        if ret > max_ret:\n",
    "            fronteira_vols.append(vol)\n",
    "            fronteira_rets.append(ret)\n",
    "            max_ret = ret\n",
    "\n",
    "    if idx_otimo is None:\n",
    "        idx_otimo = vetor_ordenacao.argmax()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sc = plt.scatter(vols_pct, retornos_pct, c=vetor_ordenacao, cmap='viridis', s=8, alpha=0.8)\n",
    "    plt.plot(fronteira_vols, fronteira_rets, color='blue', linewidth=2, label='Fronteira eficiente')\n",
    "    plt.colorbar(sc, label=label_ordenacao)\n",
    "\n",
    "    plt.scatter(vols_pct[idx_otimo], retornos_pct[idx_otimo],\n",
    "                color=cor_destaque, marker='o', s=60, label=f'M√°x. {label_ordenacao}')\n",
    "\n",
    "    if idx_vizinho is not None:\n",
    "        plt.scatter(vols_pct[idx_vizinho], retornos_pct[idx_vizinho],\n",
    "                    color='deepskyblue', marker='s', s=60, label=f'Carteira {idx_vizinho}')\n",
    "\n",
    "    plt.xlabel('Volatilidade esperada')\n",
    "    plt.ylabel('Retorno esperado')\n",
    "    plt.title(titulo)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.xticks(np.round(np.linspace(min(vols_pct), max(vols_pct), 6), 1),\n",
    "               labels=[f'{x:.1f}%' for x in np.linspace(min(vols_pct), max(vols_pct), 6)])\n",
    "    plt.yticks(np.round(np.linspace(min(retornos_pct), max(retornos_pct), 6), 1),\n",
    "               labels=[f'{x:.1f}%' for x in np.linspace(min(retornos_pct), max(retornos_pct), 6)])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_fronteira_eficiente_cyberpunk(volatilidades, retornos, vetor_ordenacao, titulo=\"Fronteira Eficiente\",\n",
    "                              label_ordenacao=\"Sharpe\", cor_destaque='red', idx_vizinho=None, idx_otimo=None):\n",
    "\n",
    "    plt.style.use(\"cyberpunk\")\n",
    "\n",
    "    retornos_aritmeticos = np.exp(retornos) - 1\n",
    "    retornos_pct = retornos_aritmeticos * 100\n",
    "    vols_pct = volatilidades * 100\n",
    "\n",
    "    indices_ordenados = np.argsort(vols_pct)\n",
    "    vols_ordenados = vols_pct[indices_ordenados]\n",
    "    retornos_ordenados = retornos_pct[indices_ordenados]\n",
    "\n",
    "    fronteira_vols = []\n",
    "    fronteira_rets = []\n",
    "    max_ret = -np.inf\n",
    "    for vol, ret in zip(vols_ordenados, retornos_ordenados):\n",
    "        if ret > max_ret:\n",
    "            fronteira_vols.append(vol)\n",
    "            fronteira_rets.append(ret)\n",
    "            max_ret = ret\n",
    "\n",
    "    if idx_otimo is None:\n",
    "        idx_otimo = vetor_ordenacao.argmax()\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sc = plt.scatter(vols_pct, retornos_pct, c=vetor_ordenacao, cmap='viridis', s=8, alpha=0.8)\n",
    "    plt.plot(fronteira_vols, fronteira_rets, color='cyan', linewidth=2, label='Fronteira eficiente')\n",
    "    plt.colorbar(sc, label=label_ordenacao)\n",
    "\n",
    "    plt.scatter(vols_pct[idx_otimo], retornos_pct[idx_otimo],\n",
    "                color=cor_destaque, marker='o', s=60, label=f'M√°x. {label_ordenacao}')\n",
    "\n",
    "    if idx_vizinho is not None:\n",
    "        plt.scatter(vols_pct[idx_vizinho], retornos_pct[idx_vizinho],\n",
    "                    color='deepskyblue', marker='s', s=60, label=f'Carteira {idx_vizinho}')\n",
    "\n",
    "    plt.xlabel('Volatilidade esperada')\n",
    "    plt.ylabel('Retorno esperado')\n",
    "    plt.title(titulo)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.xticks(np.round(np.linspace(min(vols_pct), max(vols_pct), 6), 1),\n",
    "               labels=[f'{x:.1f}%' for x in np.linspace(min(vols_pct), max(vols_pct), 6)])\n",
    "    plt.yticks(np.round(np.linspace(min(retornos_pct), max(retornos_pct), 6), 1),\n",
    "               labels=[f'{x:.1f}%' for x in np.linspace(min(retornos_pct), max(retornos_pct), 6)])\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # üî• Aplica efeitos neon do cyberpunk\n",
    "    mplcyberpunk.add_glow_effects()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1592e13d",
   "metadata": {},
   "source": [
    "## Buscar ativos e preparar dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5184410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = dt.datetime(2022, 1, 1)\n",
    "end_date = dt.datetime.today()\n",
    "# end_date = dt.datetime(2025, 10, 1)\n",
    "\n",
    "\n",
    "tickers = [\n",
    "           'PETR4.SA',\n",
    "           'ITUB4.SA',\n",
    "          #  'B3SA3.SA',\n",
    "           'BPAC11.SA', \n",
    "           'WEGE3.SA',\n",
    "           'ITSA4.SA',\n",
    "           'MSFT34.SA',\n",
    "           'NVDC34.SA',\n",
    "         #   'VALE3.SA',\n",
    "         #   'ELET3.SA',\n",
    "        #    'AAPL34.SA',\n",
    "        #    'M1TA34.SA',\n",
    "           ]\n",
    "\n",
    "\n",
    "prices = yf.download(tickers, start=start_date, end=end_date)['Close']\n",
    "prices\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd1b8e7",
   "metadata": {},
   "source": [
    "### Matriz de covari√¢ncia\n",
    "A matriz de covari√¢ncia (matrix_cov) mede como os retornos de diferentes ativos variam em rela√ß√£o uns aos outros.\n",
    "\n",
    "Cada elemento da matriz representa a covari√¢ncia entre dois ativos.\n",
    "\n",
    "Valores positivos indicam que os ativos tendem a se mover na mesma dire√ß√£o, enquanto valores negativos indicam movimentos opostos.\n",
    "\n",
    "#### Retorno logar√≠tmico vs. aritm√©tico\n",
    "O retorno logar√≠tmico √© preferido em an√°lises financeiras porque √© sim√©trico e aditivo ao longo do tempo.\n",
    "\n",
    "Isso significa que o retorno total de um per√≠odo pode ser obtido somando os retornos logar√≠tmicos di√°rios.\n",
    "\n",
    "J√° o retorno aritm√©tico (soma de %) n√£o √© aditivo devido √† composi√ß√£o, o que pode levar a erros em an√°lises de longo prazo.\n",
    "\n",
    "**Exemplo:**\n",
    "- Retorno aritm√©tico: 10% + 10% = 20% (errado pois n√£o considera a composi√ß√£o dos retornos dia a p√≥s dia)\n",
    "- Retorno logar√≠tmico: ln(1+0.10) + ln(1+0.10) = ln(1.1) + ln(1.1) = 2*ln(1.1) = ln(1.1^2) = ln(1.21) = 21% \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8763857f",
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = prices.pct_change().apply(lambda x: np.log(1+x)).dropna() # Retorno logar√≠timo\n",
    "returns_mean = returns.mean() # Media dos retornos di√°rios\n",
    "matrix_cov = returns.cov() # Matriz de covari√¢ncia dos retornos di√°rios\n",
    "\n",
    "print(\"M√©dia dos Retornos Di√°rios:\")\n",
    "print(returns_mean)\n",
    "\n",
    "print(\"\\nMatriz de Covari√¢ncia dos Retornos Di√°rios:\")\n",
    "print(matrix_cov)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccdb7d2",
   "metadata": {},
   "source": [
    "## Simula√ß√£o de Carteiras Aleat√≥rias\n",
    "\n",
    "Este trecho de c√≥digo simula 100.000 carteiras com diferentes combina√ß√µes de pesos nos ativos, a fim de avaliar seu desempenho em termos de retorno, risco e √≠ndice de Sharpe. Abaixo est√° um resumo do que acontece:\n",
    "\n",
    "- **Gera√ß√£o de pesos aleat√≥rios:** Para cada carteira, s√£o gerados pesos aleat√≥rios, para cada ativo, que somam 1 (100% do capital investido).\n",
    "- **C√°lculo do retorno esperado anual:** O retorno esperado da carteira √© calculado com base nos retornos m√©dios di√°rios dos ativos, multiplicado por 252 (dias √∫teis por ano).\n",
    "- **C√°lculo da volatilidade anual:** A volatilidade esperada da carteira √© calculada a partir da matriz de covari√¢ncia dos retornos di√°rios, tamb√©m anualizada.\n",
    "- **C√°lculo do √≠ndice de Sharpe:** Como a taxa livre de risco foi assumida como 0%, o √≠ndice de Sharpe √© apenas o retorno anual dividido pela volatilidade anual.\n",
    "- **Resultado:** Por fim, queremos a carteira com o maior √≠ndice de Sharpe, ou seja, a que oferece o melhor retorno esperado para o risco assumido.\n",
    "\n",
    "\n",
    "A simula√ß√£o gera os seguintes vetores:\n",
    "- `vetor_retornos_esperados`: retorno anual esperado de cada carteira\n",
    "- `vetor_volatilidades_esperadas`: volatilidade anual de cada carteira\n",
    "- `vetor_sharpe`: √≠ndice de Sharpe de cada carteira\n",
    "- `tabela_pesos`: pesos dos ativos em cada carteira simulada\n",
    "\n",
    "A barra de progresso da `tqdm` mostra o andamento da simula√ß√£o.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bebe46",
   "metadata": {},
   "source": [
    "### Simula√ß√£o base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415c00e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "numero_carteiras = 100000 # N√∫mero total de carteiras simulados\n",
    "vetor_retornos_esperados = np.zeros(numero_carteiras) # Vetor de retornos esperados \n",
    "vetor_volatilidades_esperadas = np.zeros(numero_carteiras) # Vetor de volatilidades esperadas\n",
    "vetor_sharpe = np.zeros(numero_carteiras) # Vetor de √≠ndices de Sharpe\n",
    "tabela_pesos = np.zeros((numero_carteiras, len(tickers))) # Tabela de pesos dos ativos\n",
    "\n",
    "# Adiciona a barra de progresso ao loop\n",
    "for k in tqdm(range(numero_carteiras), desc=\"Simulando carteiras\"):\n",
    "    pesos = np.random.random(len(tickers)) # Gera pesos aleat√≥rios\n",
    "    pesos = pesos/np.sum(pesos) # Normaliza os pesos para que a soma seja 1\n",
    "    tabela_pesos[k, :] = pesos # Adiciona os pesos √† tabela de pesos\n",
    "\n",
    "    # Calcula o retorno esperado e a volatilidade esperada da carteira\n",
    "    vetor_retornos_esperados[k] = np.sum(returns_mean * pesos) * 252 # Retorno esperado anualizado (252 dias √∫teis)\n",
    "    # Calcula a volatilidade esperada da carteira\n",
    "    vetor_volatilidades_esperadas[k] = np.sqrt(np.dot(pesos.T, np.dot(matrix_cov * 252, pesos))) # Volatilidade esperada anualizada\n",
    "\n",
    "    # Calcula o √≠ndice de Sharpe (assumindo taxa livre de risco de 0%)\n",
    "    vetor_sharpe[k] = vetor_retornos_esperados[k] / vetor_volatilidades_esperadas[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7fac98",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)  # Desativa nota√ß√£o cient√≠fica\n",
    "\n",
    "# ===============================\n",
    "# üü¢ Carteira com Sharpe M√°ximo (sem penaliza√ß√£o)\n",
    "# ===============================\n",
    "\n",
    "max_sharpe_index = vetor_sharpe.argmax()  # √çndice da carteira com maior √≠ndice de Sharpe\n",
    "melhor_carteira = tabela_pesos[max_sharpe_index, :]  # Pesos da carteira √≥tima\n",
    "\n",
    "print(\"\\n\\nüîù Carteira com maior √çndice de Sharpe (retorno m√°ximo por risco):\\n\")\n",
    "\n",
    "tabela_resultados = pd.DataFrame({\n",
    "    'Ticker': tickers,\n",
    "    'Peso (%)': [f'{peso*100:.2f}%' for peso in melhor_carteira]\n",
    "})\n",
    "print(tabela_resultados)\n",
    "\n",
    "# Retorno esperado aritm√©tico (usando log-retornos)\n",
    "tabela_retornos_esperados_aritmetica = np.exp(vetor_retornos_esperados) - 1\n",
    "\n",
    "print(f'\\nüìà Retorno esperado (1 ano): {tabela_retornos_esperados_aritmetica[max_sharpe_index]*100:.2f}%')\n",
    "print(f\"üìä √çndice de Sharpe: {vetor_sharpe[max_sharpe_index]:.4f}\")\n",
    "\n",
    "# ===============================\n",
    "# üîç Carteira \"vizinha\" ‚Äî pr√≥xima ao topo, mas com pesos diferentes\n",
    "# ===============================\n",
    "\n",
    "VIZINHO_N = 5\n",
    "\n",
    "print(\"\\n-----------------------------------------------------------------------------------------------------------\")\n",
    "print(f'\\nüîÑ Carteira {VIZINHO_N} da Vizinhan√ßa do Maior √çndice de Sharpe:')\n",
    "\n",
    "# Pega a 900¬™ melhor carteira no Sharpe tradicional\n",
    "indices_ordenados = np.argsort(vetor_sharpe)\n",
    "vizinhanca_max_sharpe_index = indices_ordenados[-(VIZINHO_N+1)]  # √çndice da carteira vizinha\n",
    "vizinhanca_carteira = tabela_pesos[vizinhanca_max_sharpe_index, :]\n",
    "\n",
    "tabela_resultados_vizinha = pd.DataFrame({\n",
    "    'Ticker': tickers,\n",
    "    'Peso (%)': [f'{peso*100:.2f}%' for peso in vizinhanca_carteira]\n",
    "})\n",
    "print(tabela_resultados_vizinha)\n",
    "\n",
    "print(f'\\nüìà Retorno esperado (1 ano): {tabela_retornos_esperados_aritmetica[vizinhanca_max_sharpe_index]*100:.2f}%')\n",
    "print(f\"üìä √çndice de Sharpe: {vetor_sharpe[vizinhanca_max_sharpe_index]:.4f}\")\n",
    "\n",
    "# ===============================\n",
    "# üßÆ Top carteiras por Sharpe (tabela completa)\n",
    "# ===============================\n",
    "\n",
    "print(\"\\n-----------------------------------------------------------------------------------------------------------\")\n",
    "df_top_sharpe = mostrar_top_carteiras(\n",
    "    vetor_ordenacao=vetor_sharpe,\n",
    "    vetor_retornos_esperados=vetor_retornos_esperados,\n",
    "    tabela_pesos=tabela_pesos,\n",
    "    tickers=tickers,\n",
    "    top_n=2000,\n",
    "    nome_ordenacao=\"Sharpe\"\n",
    ")\n",
    "\n",
    "display(df_top_sharpe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868c307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# üìâ Gr√°fico da Fronteira Eficiente\n",
    "# ===============================\n",
    "\n",
    "VIZINHO_N = 5\n",
    "\n",
    "vizinho_sharpe_index = indices_ordenados[-(VIZINHO_N+1)]\n",
    "\n",
    "grafico_fronteira_eficiente = plot_fronteira_eficiente(\n",
    "    volatilidades=vetor_volatilidades_esperadas,\n",
    "    retornos=vetor_retornos_esperados,\n",
    "    vetor_ordenacao=vetor_sharpe,\n",
    "    titulo=\"Fronteira Eficiente - Sharpe (com Vizinhan√ßa)\",\n",
    "    label_ordenacao=\"Sharpe\",\n",
    "    cor_destaque=\"darkorange\",\n",
    "    idx_vizinho=vizinho_sharpe_index\n",
    ")\n",
    "\n",
    "\n",
    "display(grafico_fronteira_eficiente)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9c3ca1",
   "metadata": {},
   "source": [
    "### Simula√ß√£o penalizada por lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a83f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Configura√ß√£o penaliza√ß√£o\n",
    "\n",
    "lambda_penalizacao = 0.4  # Par√¢metro que controla o peso da penaliza√ß√£o\n",
    "\n",
    "# ===============================================================================================\n",
    "\n",
    "numero_carteiras = 100000  # N√∫mero total de carteiras simuladas\n",
    "vetor_retornos_esperados = np.zeros(numero_carteiras)\n",
    "vetor_volatilidades_esperadas = np.zeros(numero_carteiras)\n",
    "vetor_sharpe = np.zeros(numero_carteiras)\n",
    "vetor_sharpe_penalizado = np.zeros(numero_carteiras)  # Novo vetor\n",
    "tabela_pesos = np.zeros((numero_carteiras, len(tickers)))\n",
    "\n",
    "# Loop com barra de progresso\n",
    "for k in tqdm(range(numero_carteiras), desc=\"Simulando carteiras\"):\n",
    "    pesos = np.random.random(len(tickers))\n",
    "    pesos /= np.sum(pesos)  # Normaliza\n",
    "    tabela_pesos[k, :] = pesos\n",
    "\n",
    "    # Retorno e volatilidade anualizados\n",
    "    retorno = np.sum(returns_mean * pesos) * 252\n",
    "    volatilidade = np.sqrt(np.dot(pesos.T, np.dot(matrix_cov * 252, pesos)))\n",
    "\n",
    "    vetor_retornos_esperados[k] = retorno\n",
    "    vetor_volatilidades_esperadas[k] = volatilidade\n",
    "    vetor_sharpe[k] = retorno / volatilidade\n",
    "\n",
    "    # Penalidade por concentra√ß√£o (quanto mais concentrado, maior a penalidade)\n",
    "    penalidade_concentracao = lambda_penalizacao * np.sum(pesos**2)\n",
    "    vetor_sharpe_penalizado[k] = vetor_sharpe[k] - penalidade_concentracao\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ebf9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)  # Desativa nota√ß√£o cient√≠fica\n",
    "\n",
    "# ===============================\n",
    "# üü¢ Carteira com Sharpe Penalizado M√°ximo\n",
    "# ===============================\n",
    "\n",
    "max_sharpe_pen_index = vetor_sharpe_penalizado.argmax()  # √çndice da carteira com maior Sharpe penalizado\n",
    "melhor_carteira_penalizada = tabela_pesos[max_sharpe_pen_index, :]  # Pesos da carteira √≥tima penalizada\n",
    "\n",
    "print(\"üîù Carteira com maior √çndice de Sharpe Penalizado (retorno ajustado √† diversifica√ß√£o):\\n\")\n",
    "\n",
    "tabela_resultados_pen = pd.DataFrame({\n",
    "    'Ticker': tickers,\n",
    "    'Peso (%)': [f'{peso*100:.2f}%' for peso in melhor_carteira_penalizada]\n",
    "})\n",
    "print(tabela_resultados_pen)\n",
    "\n",
    "# Retorno esperado aritm√©tico (usando log-retornos)\n",
    "tabela_retornos_esperados_aritmetica = np.exp(vetor_retornos_esperados) - 1\n",
    "\n",
    "print(f'\\nüìà Retorno esperado (1 ano): {tabela_retornos_esperados_aritmetica[max_sharpe_pen_index]*100:.2f}%')\n",
    "print(f\"üìä √çndice de Sharpe penalizado: {vetor_sharpe_penalizado[max_sharpe_pen_index]:.4f}\")\n",
    "print(f\"üìä Sharpe sem penaliza√ß√£o: {vetor_sharpe[max_sharpe_pen_index]:.4f}\")\n",
    "\n",
    "# ===============================\n",
    "# üîç Carteira \"vizinha\" ‚Äî Sharpe Penalizado\n",
    "# ===============================\n",
    "VIZINHO_N = 9\n",
    "\n",
    "print(\"\\n-----------------------------------------------------------------------------------------------------------\")\n",
    "print(f'\\nüîÑ Carteira {VIZINHO_N} da Vizinhan√ßa do Maior √çndice de Sharpe Penalizado:')\n",
    "\n",
    "indices_ordenados_pen = np.argsort(vetor_sharpe_penalizado)\n",
    "vizinhanca_max_sharpe_index_pen = indices_ordenados_pen[-(VIZINHO_N+1)]\n",
    "vizinhanca_carteira_pen = tabela_pesos[vizinhanca_max_sharpe_index_pen, :]\n",
    "\n",
    "tabela_resultados_vizinha_pen = pd.DataFrame({\n",
    "    'Ticker': tickers,\n",
    "    'Peso (%)': [f'{peso*100:.2f}%' for peso in vizinhanca_carteira_pen]\n",
    "})\n",
    "print(tabela_resultados_vizinha_pen)\n",
    "\n",
    "print(f'\\nüìà Retorno esperado (1 ano): {tabela_retornos_esperados_aritmetica[vizinhanca_max_sharpe_index_pen]*100:.2f}%')\n",
    "print(f\"üìä √çndice de Sharpe (sem penaliza√ß√£o): {vetor_sharpe[vizinhanca_max_sharpe_index_pen]:.4f}\")\n",
    "print(f\"üìä √çndice de Sharpe penalizado: {vetor_sharpe_penalizado[vizinhanca_max_sharpe_index_pen]:.4f}\")\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# üßÆ Top carteiras por Sharpe (tabela completa)\n",
    "# ===============================\n",
    "\n",
    "print(\"\\n-----------------------------------------------------------------------------------------------------------\")\n",
    "df_top_sharpe_penalizado = mostrar_top_carteiras(\n",
    "    vetor_ordenacao=vetor_sharpe_penalizado,\n",
    "    vetor_retornos_esperados=vetor_retornos_esperados,\n",
    "    tabela_pesos=tabela_pesos,\n",
    "    tickers=tickers,\n",
    "    top_n=2000,\n",
    "    nome_ordenacao=\"Sharpe Penalizado\"\n",
    ")\n",
    "\n",
    "display(df_top_sharpe_penalizado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042a3f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# üìâ Gr√°fico da Fronteira Eficiente com penaliza√ß√£o\n",
    "# ===============================\n",
    "\n",
    "VIZINHO_N = 9\n",
    "\n",
    "indices_ordenados_pen = np.argsort(vetor_sharpe_penalizado)  # ordenar pelo Sharpe penalizado\n",
    "vizinho_sharpe_index_pen = indices_ordenados_pen[-(VIZINHO_N+1)]\n",
    "\n",
    "grafico_fronteira_penalizada = plot_fronteira_eficiente(\n",
    "    volatilidades=vetor_volatilidades_esperadas,\n",
    "    retornos=vetor_retornos_esperados,\n",
    "    vetor_ordenacao=vetor_sharpe_penalizado,\n",
    "    titulo=\"Fronteira Eficiente\",\n",
    "    label_ordenacao=\"Sharpe Penalizado\",\n",
    "    cor_destaque=\"crimson\",\n",
    "    idx_vizinho=vizinho_sharpe_index_pen  # <<< AQUI\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a8b25a",
   "metadata": {},
   "source": [
    "### Simula√ß√£o com limita√ß√£o de aloca√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e2ace3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîß Configura√ß√£o de limites\n",
    "\n",
    "peso_maximo = 0.25  # Limite √∫nico global\n",
    "\n",
    "limitacao_por_ativo = False  # ‚ûï Troque para False se quiser usar limite √∫nico (ignora o global)\n",
    "limites_por_ativo = np.array([0.3, 0.3, 0.25, 0.2, 0.5])  # Um por ativo (se usado)\n",
    "\n",
    "# ===============================================================================================\n",
    "\n",
    "numero_carteiras = 100000\n",
    "vetor_retornos_esperados = np.zeros(numero_carteiras)\n",
    "vetor_volatilidades_esperadas = np.zeros(numero_carteiras)\n",
    "vetor_sharpe = np.zeros(numero_carteiras)\n",
    "tabela_pesos = np.zeros((numero_carteiras, len(tickers)))\n",
    "\n",
    "# Loop de simula√ß√£o com restri√ß√µes\n",
    "for k in tqdm(range(numero_carteiras), desc=\"Simulando carteiras com restri√ß√µes\"):\n",
    "    while True:\n",
    "        pesos = np.random.random(len(tickers))\n",
    "        pesos /= np.sum(pesos)\n",
    "\n",
    "        # Aplica a l√≥gica com base na flag\n",
    "        if limitacao_por_ativo:\n",
    "            if np.all(pesos <= limites_por_ativo):\n",
    "                break\n",
    "        else:\n",
    "            if np.all(pesos <= peso_maximo):\n",
    "                break\n",
    "\n",
    "    tabela_pesos[k, :] = pesos\n",
    "\n",
    "    retorno = np.sum(returns_mean * pesos) * 252\n",
    "    volatilidade = np.sqrt(np.dot(pesos.T, np.dot(matrix_cov * 252, pesos)))\n",
    "\n",
    "    vetor_retornos_esperados[k] = retorno\n",
    "    vetor_volatilidades_esperadas[k] = volatilidade\n",
    "    vetor_sharpe[k] = retorno / volatilidade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fb6d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "np.set_printoptions(suppress=True)  # Desativa nota√ß√£o cient√≠fica\n",
    "\n",
    "# ===============================\n",
    "# üü¢ Carteira com Sharpe M√°ximo (com restri√ß√£o de 30%)\n",
    "# ===============================\n",
    "\n",
    "max_sharpe_index = vetor_sharpe.argmax()  # √çndice da carteira com maior √≠ndice de Sharpe\n",
    "melhor_carteira = tabela_pesos[max_sharpe_index, :]  # Pesos da carteira √≥tima\n",
    "\n",
    "print(\"üîù Carteira com maior √çndice de Sharpe (com restri√ß√£o de 30% por ativo):\\n\")\n",
    "\n",
    "tabela_resultados = pd.DataFrame({\n",
    "    'Ticker': tickers,\n",
    "    'Peso (%)': [f'{peso*100:.2f}%' for peso in melhor_carteira]\n",
    "})\n",
    "print(tabela_resultados)\n",
    "\n",
    "# Retorno esperado aritm√©tico (usando log-retornos)\n",
    "tabela_retornos_esperados_aritmetica = np.exp(vetor_retornos_esperados) - 1\n",
    "\n",
    "print(f'\\nüìà Retorno esperado (1 ano): {tabela_retornos_esperados_aritmetica[max_sharpe_index]*100:.2f}%')\n",
    "print(f\"üìä √çndice de Sharpe: {vetor_sharpe[max_sharpe_index]:.4f}\")\n",
    "\n",
    "# ===============================\n",
    "# üîç Carteira \"vizinha\" ‚Äî pr√≥xima ao topo, mas com pesos diferentes\n",
    "# ===============================\n",
    "\n",
    "VIZINHO_N = 14\n",
    "\n",
    "print(\"\\n-----------------------------------------------------------------------------------------------------------\")\n",
    "print(f'\\nüîÑ Carteira {VIZINHO_N} da Vizinhan√ßa do Maior √çndice de Sharpe:')\n",
    "\n",
    "# Pega a 900¬™ melhor carteira no Sharpe tradicional\n",
    "indices_ordenados = np.argsort(vetor_sharpe)\n",
    "vizinhanca_max_sharpe_index = indices_ordenados[-(VIZINHO_N+1)]\n",
    "vizinhanca_carteira = tabela_pesos[vizinhanca_max_sharpe_index, :]\n",
    "\n",
    "tabela_resultados_vizinha = pd.DataFrame({\n",
    "    'Ticker': tickers,\n",
    "    'Peso (%)': [f'{peso*100:.2f}%' for peso in vizinhanca_carteira]\n",
    "})\n",
    "print(tabela_resultados_vizinha)\n",
    "\n",
    "print(f'\\nüìà Retorno esperado (1 ano): {tabela_retornos_esperados_aritmetica[vizinhanca_max_sharpe_index]*100:.2f}%')\n",
    "print(f\"üìä √çndice de Sharpe: {vetor_sharpe[vizinhanca_max_sharpe_index]:.4f}\")\n",
    "\n",
    "# ===============================\n",
    "# üßÆ Top carteiras por Sharpe (tabela completa)\n",
    "# ===============================\n",
    "\n",
    "print(\"\\n-----------------------------------------------------------------------------------------------------------\")\n",
    "df_top_sharpe = mostrar_top_carteiras(\n",
    "    vetor_ordenacao=vetor_sharpe,\n",
    "    vetor_retornos_esperados=vetor_retornos_esperados,\n",
    "    tabela_pesos=tabela_pesos,\n",
    "    tickers=tickers,\n",
    "    top_n=2000,\n",
    "    nome_ordenacao=\"Sharpe\"\n",
    ")\n",
    "\n",
    "display(df_top_sharpe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a5da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# üìâ Gr√°fico da Fronteira Eficiente com Restri√ß√µes de Aloca√ß√£o\n",
    "# ===============================\n",
    "\n",
    "VIZINHO_N = 153\n",
    "\n",
    "vizinho_sharpe_index = indices_ordenados[-(VIZINHO_N+1)]\n",
    "\n",
    "grafico_fronteira_com_restricao = plot_fronteira_eficiente(\n",
    "    volatilidades=vetor_volatilidades_esperadas,\n",
    "    retornos=vetor_retornos_esperados,\n",
    "    vetor_ordenacao=vetor_sharpe,\n",
    "    titulo=\"Fronteira Eficiente - Carteiras com Restri√ß√µes de Aloca√ß√£o\",\n",
    "    label_ordenacao=\"Sharpe\",\n",
    "    cor_destaque=\"seagreen\",\n",
    "    idx_vizinho=vizinho_sharpe_index\n",
    ")\n",
    "\n",
    "display(grafico_fronteira_com_restricao)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e197f2c",
   "metadata": {},
   "source": [
    "# Material Extra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9086d3",
   "metadata": {},
   "source": [
    "### üß† Simula√ß√£o de Carteiras com Penaliza√ß√£o de Markowitz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed474da2",
   "metadata": {},
   "source": [
    "Neste modelo de simula√ß√£o, aplicamos o conceito de otimiza√ß√£o de Markowitz, mas com uma **penaliza√ß√£o** adicional para desincentivar carteiras muito **concentradas** em poucos ativos.  \n",
    "A ideia √© **buscar carteiras mais diversificadas**, adicionando uma penalidade proporcional √† concentra√ß√£o dos pesos.\n",
    "\n",
    "---\n",
    "\n",
    "#### üîπ Funcionamento da Simula√ß√£o\n",
    "\n",
    "- **1.** Gera√ß√£o de 100.000 carteiras aleat√≥rias.\n",
    "- **2.** Para cada carteira:\n",
    "  - Calcula-se o **retorno esperado** anualizado.\n",
    "  - Calcula-se a **volatilidade esperada** anualizada.\n",
    "  - Calcula-se o **√çndice de Sharpe** tradicional.\n",
    "  - Aplica-se uma **penaliza√ß√£o** proporcional √† concentra√ß√£o dos pesos.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "##### 1. Retorno Esperado da Carteira\n",
    "$$\n",
    "\\mathbb{E}[R_p] = \\sum_{i=1}^{N} w_i \\cdot \\mu_i \\times 252\n",
    "$$\n",
    "Onde:\n",
    "- \\( w_i \\) = peso do ativo \\( i \\)\n",
    "- \\( \\mu_i \\) = retorno di√°rio m√©dio do ativo \\( i \\)\n",
    "- \\( 252 \\) = n√∫mero de dias √∫teis no ano (para anualizar)\n",
    "\n",
    "---\n",
    "\n",
    "##### 2. Volatilidade Esperada da Carteira\n",
    "$$\n",
    "\\sigma_p = \\sqrt{w^T \\cdot (\\Sigma \\times 252) \\cdot w}\n",
    "$$\n",
    "Onde:\n",
    "- \\( \\Sigma \\) = matriz de covari√¢ncia dos retornos di√°rios\n",
    "- \\( w \\) = vetor de pesos dos ativos\n",
    "- \\( 252 \\) = n√∫mero de dias √∫teis no ano\n",
    "\n",
    "---\n",
    "\n",
    "##### 3. √çndice de Sharpe Tradicional\n",
    "$$\n",
    "\\text{Sharpe} = \\frac{\\mathbb{E}[R_p]}{\\sigma_p}\n",
    "$$\n",
    "*(Considerando taxa livre de risco igual a 0%.)*\n",
    "\n",
    "---\n",
    "\n",
    "##### 4. Penaliza√ß√£o por Concentra√ß√£o\n",
    "Para penalizar carteiras muito concentradas, utilizamos a **soma dos quadrados dos pesos** (\\( \\sum w_i^2 \\)):\n",
    "\n",
    "$$\n",
    "\\text{Penalidade} = \\lambda \\times \\sum_{i=1}^{N} w_i^2\n",
    "$$\n",
    "Onde:\n",
    "- \\( \\lambda \\) √© o **par√¢metro de penaliza√ß√£o** (definido como 0.3 no c√≥digo).\n",
    "\n",
    "---\n",
    "\n",
    "##### 5. Sharpe Penalizado\n",
    "A f√≥rmula final usada para avaliar cada carteira √©:\n",
    "\n",
    "$$\n",
    "\\text{Sharpe Penalizado} = \\text{Sharpe Tradicional} - \\text{Penalidade}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "#### üìã Intui√ß√£o da Penaliza√ß√£o\n",
    "\n",
    "- **Se a carteira for muito concentrada** (pesos muito altos em poucos ativos), a penalidade ser√° maior.\n",
    "- **Se a carteira for bem diversificada** (pesos mais equilibrados), a penalidade ser√° pequena.\n",
    "- Assim, o algoritmo privilegia carteiras **com bom retorno por risco**, **mas tamb√©m diversificadas**.\n",
    "\n",
    "---\n",
    "\n",
    "#### üìå Conclus√£o\n",
    "\n",
    "Este m√©todo gera carteiras eficientes n√£o apenas do ponto de vista risco/retorno, mas tamb√©m **mais seguras** contra concentra√ß√£o excessiva, o que reduz o risco espec√≠fico de ativos individuais.\n",
    "\n",
    "üöÄ **Aplicando esta abordagem, voc√™ constr√≥i portf√≥lios mais robustos e resilientes!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beae8d7d",
   "metadata": {},
   "source": [
    "### Dica avan√ßada:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c95544",
   "metadata": {},
   "source": [
    "O queremos mesmo √© aperfei√ßoar a maneira de projetar a m√©dia de retorno futuro (returns_mean).\n",
    "\n",
    "Uma maneira mais avan√ßada de fazer isso √© usar a TIR (Taxa Interna de Retorno) do valuation.\n",
    "\n",
    "Se voc√™ calculcar a TIR das empresas da bolsa atrav√©s de um valuation decente, voc√™ consegue ter o retorno esperado de todas as empresas no futuro e consequentemente a volatilidade esperada tamb√©m, a partir da volatilidade impl√≠cita utilizando op√ß√µes.\n",
    "\n",
    "**Contexto: Otimiza√ß√£o de Markowitz**\n",
    "\n",
    "- Na forma cl√°ssica da otimiza√ß√£o de carteiras de Markowitz, usamos:\n",
    "\n",
    "- A m√©dia hist√≥rica dos retornos para estimar o retorno esperado (ùê∏[ùëÖ])\n",
    "\n",
    "- A matriz de covari√¢ncia hist√≥rica para representar o risco (volatilidade e correla√ß√£o entre ativos)\n",
    "\n",
    "- üí° Mas usar m√©dia hist√≥rica pode ser muito fraco para prever o futuro ‚Äî especialmente em mercados inst√°veis ou em empresas em transforma√ß√£o.\n",
    "\n",
    "**1. TIR do Valuation como proxy para retorno esperado:**\n",
    "\n",
    "- A TIR (Taxa Interna de Retorno) de um valuation √© a taxa que igualaria o pre√ßo atual de uma a√ß√£o com seus fluxos de caixa futuros esperados.\n",
    "\n",
    "- Exemplo: Se a a√ß√£o custa R$ 50 hoje e seu fluxo de caixa projetado indica que ela vai render R$ 60 em 1 ano, a TIR impl√≠cita √© de 20%.\n",
    "\n",
    "- Essa TIR pode ser interpretada como o retorno esperado daquele ativo no futuro.\n",
    "\n",
    "- ‚úÖ Isso d√° uma estimativa mais fundamentada economicamente do que a simples m√©dia dos retornos passados.\n",
    "\n",
    "**2. Volatilidade impl√≠cita (via op√ß√µes) como proxy para risco:**\n",
    "\n",
    "- Em vez de olhar a volatilidade hist√≥rica da a√ß√£o, podemos usar a volatilidade impl√≠cita ‚Äî que √© extra√≠da dos pre√ßos das op√ß√µes no mercado.\n",
    "\n",
    "- A volatilidade impl√≠cita reflete a expectativa do mercado quanto √† variabilidade dos pre√ßos no futuro.\n",
    "\n",
    "- ‚úÖ Assim, voc√™ teria uma matriz de covari√¢ncia mais condizente com as percep√ß√µes futuras do mercado.\n",
    "\n",
    "**3. Quando isso vale a pena?**\n",
    "\n",
    "- Para investidores institucionais, gestores fundamentalistas ou modelos h√≠bridos (quant + fundamental).\n",
    "\n",
    "- Quando voc√™ tem boas ferramentas para valorar empresas e capturar precifica√ß√£o de op√ß√µes.\n",
    "\n",
    "- Em mercados onde o hist√≥rico recente n√£o √© confi√°vel como proxy do futuro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc46fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "financial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
